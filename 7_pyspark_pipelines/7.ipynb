{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Здравствуйте.\n",
    "\n",
    "Spark умеет валидоровать модели. Попробуем это сделать. Evaluation ипортируется следующим образом:\n",
    "\n",
    "\n",
    "```\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator\n",
    "```\n",
    "\n",
    "В частности [RegressionEvaluator](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.RegressionEvaluator.html#pyspark.ml.evaluation.RegressionEvaluator.metricName)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Задание\n",
    "Ниже обучается и оцениваться модель. \n",
    "\n",
    "Нужно перевести этот в Pipeline (вам понадобится VectorAssembler), а затем оценить MAE с помощью spark.\n",
    "\n",
    "\n",
    "# https://scikit-learn.org/stable/datasets/toy_dataset.html#boston-dataset\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes, load_iris, load_boston\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.regression import RandomForestRegressor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[2]\")\\\n",
    "    .appName(\"Lesson_2\")\\\n",
    "    .config(\"spark.executor.instances\",2)\\\n",
    "    .config(\"spark.executor.memory\",'2g')\\\n",
    "    .config(\"spark.executor.cores\",1)\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "# load data\n",
    "data = load_boston()\n",
    "dataset = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "columns = dataset.columns.to_list()\n",
    "dataset['target'] = data['target']\n",
    "dataset.columns, dataset.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "        'PTRATIO', 'B', 'LSTAT', 'target'],\n",
       "       dtype='object'),\n",
       " (506, 14))"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "spark_dataset = spark.createDataFrame(dataset)\n",
    "assembler = VectorAssembler(inputCols=columns, outputCol='features')\n",
    "\n",
    "output = assembler.transform(spark_dataset)\n",
    "spark_dataset = output.select('features', 'target')\n",
    "train, test = spark_dataset.randomSplit([.7, .3])\n",
    "\n",
    "rf = RandomForestRegressor(labelCol='target')\n",
    "# print(\"Model was fit using parameters: \")\n",
    "# print(rf.extractParamMap())\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "preds_df = pipeline.fit(train).transform(test)\n",
    "preds_df.show(n=5, truncate=False)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol='target', predictionCol='prediction', metricName='mae')\n",
    "print('MAE:', evaluator.evaluate(preds_df))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------------------------------------------------------------------------+------+------------------+\n",
      "|features                                                                   |target|prediction        |\n",
      "+---------------------------------------------------------------------------+------+------------------+\n",
      "|[0.01439,60.0,2.93,0.0,0.401,6.604,18.8,6.2196,1.0,265.0,15.6,376.7,4.38]  |29.1  |31.63602669022915 |\n",
      "|[0.01951,17.5,1.38,0.0,0.4161,7.104,59.5,9.2229,3.0,216.0,18.6,393.24,8.05]|33.0  |29.835487987502688|\n",
      "|[0.02055,85.0,0.74,0.0,0.41,6.383,35.7,9.1876,2.0,313.0,17.3,396.9,5.77]   |24.7  |25.065775866570778|\n",
      "|[0.02729,0.0,7.07,0.0,0.469,7.185,61.1,4.9671,2.0,242.0,17.8,392.83,4.03]  |34.7  |36.12114906331665 |\n",
      "|[0.0315,95.0,1.47,0.0,0.403,6.975,15.3,7.6534,3.0,402.0,17.0,396.9,4.56]   |34.9  |32.28354268594046 |\n",
      "+---------------------------------------------------------------------------+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "MAE: 2.4472669854589757\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(rf.maxDepth, [1, 3, 5, 10])\\\n",
    "    .addGrid(rf.minInfoGain, [0.001, 0.01, 0.1, 0.15])\\\n",
    "    .addGrid(rf.numTrees, [1, 5, 10])\\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline, \n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)\n",
    "\n",
    "cvModel = crossval.fit(train)\n",
    "prediction = cvModel.transform(test)\n",
    "prediction.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+------+------------------+\n",
      "|            features|target|        prediction|\n",
      "+--------------------+------+------------------+\n",
      "|[0.01439,60.0,2.9...|  29.1|27.014500000000005|\n",
      "|[0.01951,17.5,1.3...|  33.0|30.799666666666667|\n",
      "|[0.02055,85.0,0.7...|  24.7|23.592718614718613|\n",
      "|[0.02729,0.0,7.07...|  34.7| 36.53045238095238|\n",
      "|[0.0315,95.0,1.47...|  34.9|30.619982456140356|\n",
      "|[0.03237,0.0,2.18...|  33.4|32.294999999999995|\n",
      "|[0.03359,75.0,2.9...|  34.9|           32.3495|\n",
      "|[0.03932,0.0,3.41...|  22.0|24.985611111111115|\n",
      "|[0.0456,0.0,13.89...|  23.3|24.041438095238096|\n",
      "|[0.04684,0.0,3.41...|  22.6| 23.91561111111111|\n",
      "|[0.05302,0.0,3.41...|  28.7|27.488253968253968|\n",
      "|[0.05735,0.0,4.49...|  26.6| 27.52709523809524|\n",
      "|[0.0578,0.0,2.46,...|  37.2| 32.32928571428572|\n",
      "|[0.06047,0.0,2.46...|  29.6|           26.1615|\n",
      "|[0.06642,0.0,4.05...|  29.9|27.270522875816994|\n",
      "|[0.06888,0.0,2.46...|  36.2|           23.8765|\n",
      "|[0.06899,0.0,25.6...|  22.0| 20.01249458874459|\n",
      "|[0.07022,0.0,4.05...|  23.2|22.524948677248677|\n",
      "|[0.07165,0.0,25.6...|  20.3| 19.79944264069264|\n",
      "|[0.08014,0.0,5.96...|  21.0| 21.52158095238095|\n",
      "+--------------------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "import numpy as np\n",
    "print(cvModel.getEstimatorParamMaps()[np.argmax(cvModel.avgMetrics)])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{Param(parent='RandomForestRegressor_324dc6cae1db', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 1, Param(parent='RandomForestRegressor_324dc6cae1db', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.001, Param(parent='RandomForestRegressor_324dc6cae1db', name='numTrees', doc='Number of trees to train (>= 1).'): 1}\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "32086f9b7cc52bc2c8629421cf6cba175094c2e18299455caf64f8eb675094c9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}