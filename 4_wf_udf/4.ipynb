{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lag\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql.functions import round\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[2]\")\\\n",
    "    .appName(\"Lesson_2\")\\\n",
    "    .config(\"spark.executor.instances\",2)\\\n",
    "    .config(\"spark.executor.memory\",'2g')\\\n",
    "    .config(\"spark.executor.cores\",1)\\\n",
    "    .getOrCreate()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Самостоятельная работа к уроку 4\n",
    "На уроке мы попробовали оконные и пользовательские функции. Теперь закрепим полученные знания.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Данные: [google drive: raw_sales.csv](https://drive.google.com/file/d/1G2N7Mnt4-Tqz4JdJxutGDMbJiOr32kZp/view?usp=sharing)\n",
    "\n",
    " Каждая строчка это продажа жилья, которая состоит из следующих полей (думаю описание не требуется):\n",
    "*   date of sale\n",
    "*   price\n",
    "*   property type\n",
    "*   number of bedrooms\n",
    "*   4digit postcode\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "data = spark.read.csv('raw_sales.csv', header=True, inferSchema=True)\n",
    "data = data.select(data.datesold.cast('date').alias('datesold'), 'postcode', 'price', 'propertyType', 'bedrooms')\n",
    "data.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- datesold: date (nullable = true)\n",
      " |-- postcode: integer (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- propertyType: string (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Задание 1\n",
    "Добавьте к таблице следующие поля:\n",
    "*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode) (1 балл)\n",
    "*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode) (1 балл)\n",
    "*  Стоимость последнего проданного дома до текущего (1 балл)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "data.createOrReplaceTempView('window')\n",
    "w = spark.sql('''SELECT *, AVG(price)\n",
    "                        OVER (PARTITION BY postcode \n",
    "                        ORDER BY datesold\n",
    "                        ROWS BETWEEN 10 PRECEDING AND 1 PRECEDING ) \n",
    "                        AS last10_avg_price,\n",
    "                        AVG(price) \n",
    "                        OVER (PARTITION BY postcode\n",
    "                        ORDER BY datesold\n",
    "                        ROWS BETWEEN 1 FOLLOWING AND 10 FOLLOWING )\n",
    "                        AS fw10_avg_price, \n",
    "                        LAG(price) \n",
    "                        OVER (PARTITION BY postcode \n",
    "                        ORDER BY datesold) AS prev_price\n",
    "                        FROM window''')\n",
    "\n",
    "\n",
    "w.select('datesold', 'postcode', \n",
    "                  'propertyType', 'bedrooms', \n",
    "                  'price', round('last10_avg_price', 0).alias('last10_avg_price'), \n",
    "                  round('fw10_avg_price', 0).alias('fw_10_avg_price'), \n",
    "                  'window.prev_price').show(n=15)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------+------------+--------+------+----------------+---------------+----------+\n",
      "|  datesold|postcode|propertyType|bedrooms| price|last10_avg_price|fw_10_avg_price|prev_price|\n",
      "+----------+--------+------------+--------+------+----------------+---------------+----------+\n",
      "|2007-07-02|    2914|       house|       5|800000|            null|       502800.0|      null|\n",
      "|2008-06-17|    2914|       house|       4|600000|        800000.0|       486800.0|    800000|\n",
      "|2008-08-29|    2914|       house|       4|465000|        700000.0|       487800.0|    600000|\n",
      "|2008-09-02|    2914|       house|       4|541000|        621667.0|       481450.0|    465000|\n",
      "|2008-09-05|    2914|       house|       3|395000|        601500.0|       495950.0|    541000|\n",
      "|2008-09-05|    2914|       house|       4|552000|        560200.0|       500750.0|    395000|\n",
      "|2008-09-17|    2914|       house|       3|410000|        558833.0|       505350.0|    552000|\n",
      "|2008-09-26|    2914|       house|       4|755000|        537571.0|       474250.0|    410000|\n",
      "|2008-10-14|    2914|       house|       4|420000|        564750.0|       472250.0|    755000|\n",
      "|2008-10-16|    2914|       house|       3|375000|        548667.0|       475750.0|    420000|\n",
      "|2008-10-21|    2914|       house|       4|515000|        531300.0|       480250.0|    375000|\n",
      "|2008-10-27|    2914|       house|       3|440000|        502800.0|       494750.0|    515000|\n",
      "|2008-10-27|    2914|       house|       4|475000|        486800.0|       510250.0|    440000|\n",
      "|2008-11-05|    2914|       house|       4|477500|        487800.0|       537500.0|    475000|\n",
      "|2008-11-18|    2914|       house|       4|540000|        481450.0|       523500.0|    477500|\n",
      "+----------+--------+------------+--------+------+----------------+---------------+----------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "# a = spark.sql(\"\"\"SELECT year(datesold) year, round(avg(price), 0) average_price FROM window group by year\"\"\")\n",
    "# b = spark.sql(\"\"\"SELECT *, YEAR(datesold) year FROM window\"\"\")\n",
    "# a.join(b, ['year'], how='full').show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "window = Window.partitionBy('postcode').orderBy('datesold')\n",
    "\n",
    "data = data.withColumn('last10_avg', avg('price')\\\n",
    "        .over(window.rowsBetween(Window.currentRow - 10, Window.currentRow - 1)))\\\n",
    "    .withColumn('fw10_avg', avg('price')\\\n",
    "        .over(window.rowsBetween(Window.currentRow + 1, Window.currentRow + 10)))\\\n",
    "    .withColumn('prev_price', lag('price')\\\n",
    "        .over(window))\n",
    " \n",
    "    \n",
    "data.show(n=10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------+------+------------+--------+-----------------+--------+----------+\n",
      "|  datesold|postcode| price|propertyType|bedrooms|       last10_avg|fw10_avg|prev_price|\n",
      "+----------+--------+------+------------+--------+-----------------+--------+----------+\n",
      "|2007-07-02|    2914|800000|       house|       5|             null|502800.0|      null|\n",
      "|2008-06-17|    2914|600000|       house|       4|         800000.0|486800.0|    800000|\n",
      "|2008-08-29|    2914|465000|       house|       4|         700000.0|487800.0|    600000|\n",
      "|2008-09-02|    2914|541000|       house|       4|621666.6666666666|481450.0|    465000|\n",
      "|2008-09-05|    2914|395000|       house|       3|         601500.0|495950.0|    541000|\n",
      "|2008-09-05|    2914|552000|       house|       4|         560200.0|500750.0|    395000|\n",
      "|2008-09-17|    2914|410000|       house|       3|558833.3333333334|505350.0|    552000|\n",
      "|2008-09-26|    2914|755000|       house|       4|537571.4285714285|474250.0|    410000|\n",
      "|2008-10-14|    2914|420000|       house|       4|         564750.0|472250.0|    755000|\n",
      "|2008-10-16|    2914|375000|       house|       3|548666.6666666666|475750.0|    420000|\n",
      "+----------+--------+------+------------+--------+-----------------+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Задание 2\n",
    "В итоге у вас таблица с колонками (или нечто похожее):\n",
    "*   price\n",
    "*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode) (1 балл)\n",
    "*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode) (1 балл)\n",
    "*  Стоимость последнего проданного дома до текущего ((1 балл)\n",
    "*  и др.\n",
    "\n",
    "Посчитайте кол-во уникальных значений в каждой строчке (unique(row)). (2 балла)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "print('UNIQUE COUNTS by column:')\n",
    "for row in data.columns:\n",
    "    cnt = data.select(row).distinct().count()\n",
    "    print(row, ':', cnt)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "UNIQUE COUNTS by column:\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "datesold : 3582\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "postcode : 27\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "price : 2554\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "propertyType : 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bedrooms : 6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "last10_avg : 16097\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fw10_avg : 16100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "prev_price : 2553\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Задание 3\n",
    "SQL like case when или if elif else\n",
    "\n",
    "Создайте колонку, в которой в которой будет отображаться \"+\", \"-\" или \"=\", если \"Средняя стомость 10 проданных домов до текущего в том же районе\" больше, меньше или равно \"Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode)\", соотвественно.\n",
    "\n",
    "Если одно из полей Null, запишите в эту колонку \"Нет данных\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "data = data.withColumn(\"rolling_avg_comp\", when(data.last10_avg > data.fw10_avg, '+')\n",
    "                                          .when(data.last10_avg < data.fw10_avg, '-')\n",
    "                                          .when(data.last10_avg == data.fw10_avg, '=')\n",
    "                                          .otherwise('Нет данных')).show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------+------+------------+--------+-----------------+--------+----------+----------------+\n",
      "|  datesold|postcode| price|propertyType|bedrooms|       last10_avg|fw10_avg|prev_price|rolling_avg_comp|\n",
      "+----------+--------+------+------------+--------+-----------------+--------+----------+----------------+\n",
      "|2007-07-02|    2914|800000|       house|       5|             null|502800.0|      null|      Нет данных|\n",
      "|2008-06-17|    2914|600000|       house|       4|         800000.0|486800.0|    800000|               +|\n",
      "|2008-08-29|    2914|465000|       house|       4|         700000.0|487800.0|    600000|               +|\n",
      "|2008-09-02|    2914|541000|       house|       4|621666.6666666666|481450.0|    465000|               +|\n",
      "|2008-09-05|    2914|395000|       house|       3|         601500.0|495950.0|    541000|               +|\n",
      "|2008-09-05|    2914|552000|       house|       4|         560200.0|500750.0|    395000|               +|\n",
      "|2008-09-17|    2914|410000|       house|       3|558833.3333333334|505350.0|    552000|               +|\n",
      "|2008-09-26|    2914|755000|       house|       4|537571.4285714285|474250.0|    410000|               +|\n",
      "|2008-10-14|    2914|420000|       house|       4|         564750.0|472250.0|    755000|               +|\n",
      "|2008-10-16|    2914|375000|       house|       3|548666.6666666666|475750.0|    420000|               +|\n",
      "|2008-10-21|    2914|515000|       house|       4|         531300.0|480250.0|    375000|               +|\n",
      "|2008-10-27|    2914|440000|       house|       3|         502800.0|494750.0|    515000|               +|\n",
      "|2008-10-27|    2914|475000|       house|       4|         486800.0|510250.0|    440000|               -|\n",
      "|2008-11-05|    2914|477500|       house|       4|         487800.0|537500.0|    475000|               -|\n",
      "|2008-11-18|    2914|540000|       house|       4|         481450.0|523500.0|    477500|               -|\n",
      "|2008-12-06|    2914|600000|       house|       4|         495950.0|508500.0|    540000|               -|\n",
      "|2008-12-22|    2914|456000|       house|       3|         500750.0|515400.0|    600000|               -|\n",
      "|2008-12-23|    2914|444000|       house|       4|         505350.0|517800.0|    456000|               -|\n",
      "|2008-12-24|    2914|400000|       house|       4|         474250.0|521300.0|    444000|               -|\n",
      "|2009-01-08|    2914|410000|       house|       4|         472250.0|515800.0|    400000|               -|\n",
      "+----------+--------+------+------------+--------+-----------------+--------+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "32086f9b7cc52bc2c8629421cf6cba175094c2e18299455caf64f8eb675094c9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}