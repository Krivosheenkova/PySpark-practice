{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.master('local[4]').appName('hw6').getOrCreate()\n",
    "\n",
    "# создаём датафрейм\n",
    "words = spark.createDataFrame(\n",
    "    [(1, 'look',), (1, 'spark',), (1, 'tutorial',), (1, 'spark',), (1, 'look', ), (1, 'python', ), (1, 'geek', ), \n",
    "     (2, 'brain', ), (2, 'homework', ), (2, 'lesson', ), (2, 'wheel', ), (2, 'pyspark', ), (2, 'session', ), (2, 'pyspark', ), ], \n",
    "    ['group', 'word'])\n",
    "words.show()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+--------+\n",
      "|group|    word|\n",
      "+-----+--------+\n",
      "|    1|    look|\n",
      "|    1|   spark|\n",
      "|    1|tutorial|\n",
      "|    1|   spark|\n",
      "|    1|    look|\n",
      "|    1|  python|\n",
      "|    1|    geek|\n",
      "|    2|   brain|\n",
      "|    2|homework|\n",
      "|    2|  lesson|\n",
      "|    2|   wheel|\n",
      "|    2| pyspark|\n",
      "|    2| session|\n",
      "|    2| pyspark|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Задание 1\n",
    "Выведите все уникальные слова для каждой группы (используйте collect_set).\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "uniq_table = words.groupBy('group').agg(F.collect_set('word').alias('words'))\n",
    "uniq_table.dtypes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('group', 'bigint'), ('words', 'array<string>')]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Задание 2\n",
    "Выведите все уникальные слова для каждой группы (используйте pandas_udf: pyspark.sql.GroupedData.applyInPandas).\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# from pyspark.sql.functions import pandas_udf\n",
    "# from pyspark.sql.types import StringType\n",
    "\n",
    "# # @pandas_udf(StringType())\n",
    "# def print_word(df):\n",
    "#     for col in df.columns:\n",
    "#         print(df[col])\n",
    "\n",
    "# words.groupby('group').applyInPandas(print_word, schema='group bigint, word array<string>').show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "# Задание 3\n",
    "Вы собрали уникальные слова для каждой группы, теперь на основе полученной таблицы, посчитайте кол-во слов. Есть несколько способов, один из них  - [Accumulator](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.AccumulatorParam.html#pyspark.AccumulatorParam)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Из таблицы:\n",
    "# +-----+--------------------------------------------------+\n",
    "# |group|                                      unique_words|  \n",
    "# +-----+--------------------------------------------------+  \n",
    "# |    1|             [tutorial, geek, spark, look, python]|  \n",
    "# |    2|[homework, wheel, session, brain, lesson, pyspark]|  \n",
    "# +-----+--------------------------------------------------+\n",
    "# нужно получить таблицу:\n",
    "# +--------+-----+\n",
    "# |    word|count|\n",
    "# +--------+-----+\n",
    "# |tutorial|    1|\n",
    "# |   spark|    2|\n",
    "# |    look|    2|\n",
    "# |  python|    1|\n",
    "# |homework|    1|\n",
    "# |    geek|    1|\n",
    "# |   brain|    1|\n",
    "# | session|    1|\n",
    "# |  lesson|    1|\n",
    "# |   wheel|    1|\n",
    "# | pyspark|    2|\n",
    "# +--------+-----+\n",
    "# либо питоновский словарь, если делать чреез accumulators."
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "32086f9b7cc52bc2c8629421cf6cba175094c2e18299455caf64f8eb675094c9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}